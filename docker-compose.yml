version: "3.8"

services:
  
  # Inference Engine to Run Predictions
  # Popping out of the MQ
  inference-engine:
    build: 
        context: .
        dockerfile: ./inference_engine/Dockerfile
    restart: on-failure
    depends_on:
      - rabbitmq
      - database
      - server
    networks:
      - webnet

  # RabbitMQ for Message Queueing to handle
  # predictions in FIFO 
  rabbitmq:
    image: "rabbitmq:3-management"
    ports:
      - "5672:5672"
      - "15672:15672"
    hostname: rabbitmq
    volumes:
        - rabbitmq_data
    networks:
      - webnet

  # SQL Database to handle transactions
  database:
    image: mysql
    hostname: database
    ports:
        - "3306:3306"
    command: 
        --sort_buffer_size=100000000
    volumes:
        - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql
    environment:
        MYSQL_ROOT_USER: admin
        MYSQL_ROOT_PASSWORD: rootpassword
        MYSQL_USER: user
        MYSQL_PASSWORD: userpassword
    networks:
      - webnet

  # Web Server with REST endpoints for predictions
  server:
    build: 
        context: .
        dockerfile: ./server/Dockerfile
    ports:
      - "5000:5000"
    depends_on:
      - database
      - rabbitmq
    restart: on-failure
    networks:
      - webnet

# Set up a bridge for all containers
networks:
  webnet: